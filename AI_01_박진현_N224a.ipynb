{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "AI_01_박진현_N224a.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JinHyun-P/HelloGit/blob/master/AI_01_%E1%84%87%E1%85%A1%E1%86%A8%E1%84%8C%E1%85%B5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%AB_N224a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmnZ5a8X_JGX"
      },
      "source": [
        "<img align=\"right\" src=\"https://ds-cs-images.s3.ap-northeast-2.amazonaws.com/Codestates_Fulllogo_Color.png\" width=100>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 2 / SPRINT 2 / NOTE 4*\n",
        "\n",
        "# 📝 Assignment\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iez7-3tEM5Qi"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "target = 'vacc_h1n1_f'\n",
        "# target = 'vacc_seas_f'\n",
        "train = pd.merge(pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train.csv'), \n",
        "                 pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/train_labels.csv')[target], left_index=True, right_index=True)\n",
        "test = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/test.csv')\n",
        "sample_submission = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/vacc_flu/submission.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAuwF2H7NG8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8c7e8f-1406-45d3-8683-d7b482b1623b"
      },
      "source": [
        "# 훈련데이터를 훈련/검증 데이터로 나누기\n",
        "\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train[target], random_state=2)\n",
        "\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((33723, 39), (8431, 39), (28104, 38))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czu0fy81O279"
      },
      "source": [
        "# 특성공학\n",
        "\n",
        "def engineer(df):\n",
        "\n",
        "  # behavioral 컬럼 통합하기\n",
        "  \n",
        "  behaviorals = [col for col in df.columns if 'behavioral' in col]\n",
        "  df['behaviorals'] = df[behaviorals].sum(axis=1)\n",
        "\n",
        "  # 높은 카디널리티 가지는 특성 제거\n",
        "\n",
        "  selected_cols = df.select_dtypes(include=['number', 'object'])\n",
        "  labels = selected_cols.nunique() # 특성별 카디널리티 리스트\n",
        "  selected_features = labels[labels <= 30].index.tolist() # 카디널리티가 30보다 작은 특성만 선택\n",
        "  \n",
        "  # 상관없는 데이터 삭제\n",
        "\n",
        "  dels = [col for col in df.columns if ('employment' in col or 'seas' in col)]\n",
        "  df.drop(columns=dels, inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "train = engineer(train)\n",
        "val = engineer(val)\n",
        "test = engineer(test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aw5WpxdeO8jx"
      },
      "source": [
        "# 데이터에서 타겟과 특성 분리\n",
        "\n",
        "features = train.drop(columns=[target]).columns"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wUIzEUmO9pg"
      },
      "source": [
        "# 훈련/검증/테스트 데이터를 특성과 타겟으로 분리\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoBPg5MMQP-W"
      },
      "source": [
        "# !pip install category_encoders"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vR4JhnqQkVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575ef060-f0ce-4c73-c270-1035cb9faa5b"
      },
      "source": [
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx7tWZ_ZQAuR"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5J4W0o8_JGm"
      },
      "source": [
        "# 모델선택(Model Selection)\n",
        "\n",
        "### 1) 캐글 대회를 이어서 진행합니다. RandomizedSearchCV 를 사용하여 하이퍼파라미터 튜닝을 진행합니다.\n",
        "\n",
        "주의해야 할 점은, 이번에는 [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)를 사용한다는 점입니다.\n",
        "\n",
        "또한 분류문제에서 맞는 [`scoring='accuracy'`](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values) 같은 metric을 사용해야 합니다.\n",
        "\n",
        "그리고 인코더 사용에도 주의 해야 하는데, 지금 다루는 분류 문제에서는 [OrdinalEncoder](https://contrib.scikit-learn.org/categorical-encoding/ordinal.html)사용을 추천합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoJ41M-n_JGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda313ea-b3dc-4cab-94f5-65e2b2b4b91c"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "pipe = make_pipeline(\n",
        "    TargetEncoder(), \n",
        "    SimpleImputer(), \n",
        "    RandomForestRegressor(random_state=2)\n",
        ")\n",
        "\n",
        "dists = {\n",
        "    'targetencoder__smoothing': [2.,20.,50.,60.,100.,500.,1000.], # int로 넣으면 error(bug)\n",
        "    'targetencoder__min_samples_leaf': randint(1, 10),     \n",
        "    'simpleimputer__strategy': ['mean', 'median'], \n",
        "    'randomforestregressor__n_estimators': randint(100, 500), \n",
        "    'randomforestregressor__max_depth': [5, 10, 15, 20, None], \n",
        "    #'randomforestregressor__max_features': uniform(0, 1) # max_features\n",
        "}\n",
        "\n",
        "clf = RandomizedSearchCV(\n",
        "    pipe, \n",
        "    param_distributions=dists, \n",
        "    n_iter=50, \n",
        "    cv=3, \n",
        "    scoring='neg_mean_absolute_error',  \n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train);"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 57.9min finished\n",
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryRS7_KmYMtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3228e21-8228-4d44-f09e-2f5de97cee93"
      },
      "source": [
        "print('최적 하이퍼파라미터: ', clf.best_params_)\n",
        "print('MAE: ', -clf.best_score_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최적 하이퍼파라미터:  {'randomforestregressor__max_depth': 10, 'randomforestregressor__n_estimators': 242, 'simpleimputer__strategy': 'mean', 'targetencoder__min_samples_leaf': 1, 'targetencoder__smoothing': 50.0}\n",
            "MAE:  0.2498114708357595\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "T03fw7pJMYTB",
        "outputId": "15d5da60-4d2a-4089-f9c5-4b3e53df25c1"
      },
      "source": [
        "# 각 하이퍼파라미터 모델들 순위별로 나열\n",
        "\n",
        "pd.DataFrame(clf.cv_results_).sort_values(by='rank_test_score').T"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>25</th>\n",
              "      <th>15</th>\n",
              "      <th>27</th>\n",
              "      <th>17</th>\n",
              "      <th>40</th>\n",
              "      <th>23</th>\n",
              "      <th>14</th>\n",
              "      <th>20</th>\n",
              "      <th>11</th>\n",
              "      <th>47</th>\n",
              "      <th>34</th>\n",
              "      <th>24</th>\n",
              "      <th>45</th>\n",
              "      <th>12</th>\n",
              "      <th>0</th>\n",
              "      <th>29</th>\n",
              "      <th>1</th>\n",
              "      <th>16</th>\n",
              "      <th>39</th>\n",
              "      <th>32</th>\n",
              "      <th>46</th>\n",
              "      <th>31</th>\n",
              "      <th>21</th>\n",
              "      <th>7</th>\n",
              "      <th>3</th>\n",
              "      <th>37</th>\n",
              "      <th>33</th>\n",
              "      <th>22</th>\n",
              "      <th>8</th>\n",
              "      <th>26</th>\n",
              "      <th>4</th>\n",
              "      <th>35</th>\n",
              "      <th>5</th>\n",
              "      <th>48</th>\n",
              "      <th>2</th>\n",
              "      <th>42</th>\n",
              "      <th>6</th>\n",
              "      <th>19</th>\n",
              "      <th>18</th>\n",
              "      <th>43</th>\n",
              "      <th>30</th>\n",
              "      <th>38</th>\n",
              "      <th>9</th>\n",
              "      <th>44</th>\n",
              "      <th>41</th>\n",
              "      <th>10</th>\n",
              "      <th>13</th>\n",
              "      <th>36</th>\n",
              "      <th>49</th>\n",
              "      <th>28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean_fit_time</th>\n",
              "      <td>31.4534</td>\n",
              "      <td>55.7421</td>\n",
              "      <td>55.6367</td>\n",
              "      <td>62.4537</td>\n",
              "      <td>58.4264</td>\n",
              "      <td>63.0372</td>\n",
              "      <td>62.5256</td>\n",
              "      <td>20.4431</td>\n",
              "      <td>38.4495</td>\n",
              "      <td>18.7128</td>\n",
              "      <td>42.0744</td>\n",
              "      <td>13.4821</td>\n",
              "      <td>19.919</td>\n",
              "      <td>27.0231</td>\n",
              "      <td>39.2065</td>\n",
              "      <td>37.2036</td>\n",
              "      <td>32.4397</td>\n",
              "      <td>48.52</td>\n",
              "      <td>69.5897</td>\n",
              "      <td>79.0459</td>\n",
              "      <td>77.7448</td>\n",
              "      <td>17.0617</td>\n",
              "      <td>39.4789</td>\n",
              "      <td>8.50832</td>\n",
              "      <td>13.2706</td>\n",
              "      <td>7.75873</td>\n",
              "      <td>16.0278</td>\n",
              "      <td>26.7208</td>\n",
              "      <td>67.6163</td>\n",
              "      <td>33.5822</td>\n",
              "      <td>19.361</td>\n",
              "      <td>23.3586</td>\n",
              "      <td>35.4004</td>\n",
              "      <td>30.27</td>\n",
              "      <td>46.426</td>\n",
              "      <td>63.8026</td>\n",
              "      <td>68.7943</td>\n",
              "      <td>66.5836</td>\n",
              "      <td>77.0123</td>\n",
              "      <td>45.0936</td>\n",
              "      <td>63.2293</td>\n",
              "      <td>63.2064</td>\n",
              "      <td>67.2405</td>\n",
              "      <td>61.63</td>\n",
              "      <td>45.1617</td>\n",
              "      <td>86.9902</td>\n",
              "      <td>49.6466</td>\n",
              "      <td>50.753</td>\n",
              "      <td>61.8648</td>\n",
              "      <td>40.9381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_fit_time</th>\n",
              "      <td>0.424569</td>\n",
              "      <td>0.187859</td>\n",
              "      <td>0.45665</td>\n",
              "      <td>1.75265</td>\n",
              "      <td>0.45804</td>\n",
              "      <td>0.246395</td>\n",
              "      <td>0.253583</td>\n",
              "      <td>0.0469282</td>\n",
              "      <td>0.487115</td>\n",
              "      <td>0.173874</td>\n",
              "      <td>0.815974</td>\n",
              "      <td>0.141508</td>\n",
              "      <td>0.0158306</td>\n",
              "      <td>0.233884</td>\n",
              "      <td>0.961659</td>\n",
              "      <td>1.10828</td>\n",
              "      <td>0.416098</td>\n",
              "      <td>0.258811</td>\n",
              "      <td>0.433115</td>\n",
              "      <td>2.82206</td>\n",
              "      <td>0.691849</td>\n",
              "      <td>0.267688</td>\n",
              "      <td>0.418564</td>\n",
              "      <td>0.0799884</td>\n",
              "      <td>0.093593</td>\n",
              "      <td>0.0990425</td>\n",
              "      <td>0.248607</td>\n",
              "      <td>0.221727</td>\n",
              "      <td>0.788864</td>\n",
              "      <td>0.320052</td>\n",
              "      <td>0.267377</td>\n",
              "      <td>0.484465</td>\n",
              "      <td>0.418694</td>\n",
              "      <td>0.541973</td>\n",
              "      <td>0.550611</td>\n",
              "      <td>0.470794</td>\n",
              "      <td>0.691229</td>\n",
              "      <td>0.58755</td>\n",
              "      <td>0.298761</td>\n",
              "      <td>0.487491</td>\n",
              "      <td>0.949443</td>\n",
              "      <td>0.347516</td>\n",
              "      <td>0.68329</td>\n",
              "      <td>0.170139</td>\n",
              "      <td>0.435053</td>\n",
              "      <td>0.373996</td>\n",
              "      <td>0.227444</td>\n",
              "      <td>0.232415</td>\n",
              "      <td>7.48483</td>\n",
              "      <td>0.330603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_score_time</th>\n",
              "      <td>0.772504</td>\n",
              "      <td>1.36362</td>\n",
              "      <td>1.15144</td>\n",
              "      <td>1.45067</td>\n",
              "      <td>0.813866</td>\n",
              "      <td>1.46024</td>\n",
              "      <td>1.54251</td>\n",
              "      <td>0.496655</td>\n",
              "      <td>0.951452</td>\n",
              "      <td>0.337259</td>\n",
              "      <td>0.860469</td>\n",
              "      <td>0.224165</td>\n",
              "      <td>0.31853</td>\n",
              "      <td>0.383719</td>\n",
              "      <td>0.676702</td>\n",
              "      <td>0.798674</td>\n",
              "      <td>0.586864</td>\n",
              "      <td>1.16838</td>\n",
              "      <td>1.27882</td>\n",
              "      <td>1.79798</td>\n",
              "      <td>1.37096</td>\n",
              "      <td>0.461817</td>\n",
              "      <td>0.989322</td>\n",
              "      <td>0.174136</td>\n",
              "      <td>0.217456</td>\n",
              "      <td>0.153252</td>\n",
              "      <td>0.262597</td>\n",
              "      <td>0.419331</td>\n",
              "      <td>1.75979</td>\n",
              "      <td>0.845174</td>\n",
              "      <td>0.476575</td>\n",
              "      <td>0.621866</td>\n",
              "      <td>0.856194</td>\n",
              "      <td>0.60497</td>\n",
              "      <td>0.881477</td>\n",
              "      <td>1.18796</td>\n",
              "      <td>1.87558</td>\n",
              "      <td>1.84536</td>\n",
              "      <td>2.09854</td>\n",
              "      <td>0.858572</td>\n",
              "      <td>1.7644</td>\n",
              "      <td>1.40705</td>\n",
              "      <td>1.70461</td>\n",
              "      <td>1.18867</td>\n",
              "      <td>0.870536</td>\n",
              "      <td>2.35697</td>\n",
              "      <td>1.39304</td>\n",
              "      <td>1.38121</td>\n",
              "      <td>1.30743</td>\n",
              "      <td>1.09684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_score_time</th>\n",
              "      <td>0.0108714</td>\n",
              "      <td>0.0173312</td>\n",
              "      <td>0.0722374</td>\n",
              "      <td>0.102506</td>\n",
              "      <td>0.0261774</td>\n",
              "      <td>0.131571</td>\n",
              "      <td>0.0494456</td>\n",
              "      <td>0.0442974</td>\n",
              "      <td>0.0321336</td>\n",
              "      <td>0.0230631</td>\n",
              "      <td>0.179785</td>\n",
              "      <td>0.0126627</td>\n",
              "      <td>0.0342575</td>\n",
              "      <td>0.00895355</td>\n",
              "      <td>0.00882858</td>\n",
              "      <td>0.0333836</td>\n",
              "      <td>0.0337765</td>\n",
              "      <td>0.109987</td>\n",
              "      <td>0.105699</td>\n",
              "      <td>0.176043</td>\n",
              "      <td>0.0573177</td>\n",
              "      <td>0.00966811</td>\n",
              "      <td>0.0508017</td>\n",
              "      <td>0.0089648</td>\n",
              "      <td>0.00609356</td>\n",
              "      <td>0.00272752</td>\n",
              "      <td>0.00603878</td>\n",
              "      <td>0.00570137</td>\n",
              "      <td>0.0802765</td>\n",
              "      <td>0.10752</td>\n",
              "      <td>0.076392</td>\n",
              "      <td>0.0774572</td>\n",
              "      <td>0.136162</td>\n",
              "      <td>0.0191573</td>\n",
              "      <td>0.069087</td>\n",
              "      <td>0.0355607</td>\n",
              "      <td>0.0564046</td>\n",
              "      <td>0.0139631</td>\n",
              "      <td>0.00730764</td>\n",
              "      <td>0.0299363</td>\n",
              "      <td>0.0075913</td>\n",
              "      <td>0.0947252</td>\n",
              "      <td>0.082981</td>\n",
              "      <td>0.0603689</td>\n",
              "      <td>0.0224479</td>\n",
              "      <td>0.0294484</td>\n",
              "      <td>0.0367937</td>\n",
              "      <td>0.0780717</td>\n",
              "      <td>0.0660615</td>\n",
              "      <td>0.061287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_randomforestregressor__max_depth</th>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_randomforestregressor__n_estimators</th>\n",
              "      <td>242</td>\n",
              "      <td>421</td>\n",
              "      <td>436</td>\n",
              "      <td>486</td>\n",
              "      <td>499</td>\n",
              "      <td>480</td>\n",
              "      <td>477</td>\n",
              "      <td>152</td>\n",
              "      <td>226</td>\n",
              "      <td>116</td>\n",
              "      <td>262</td>\n",
              "      <td>186</td>\n",
              "      <td>306</td>\n",
              "      <td>385</td>\n",
              "      <td>228</td>\n",
              "      <td>208</td>\n",
              "      <td>190</td>\n",
              "      <td>258</td>\n",
              "      <td>396</td>\n",
              "      <td>434</td>\n",
              "      <td>443</td>\n",
              "      <td>141</td>\n",
              "      <td>318</td>\n",
              "      <td>129</td>\n",
              "      <td>223</td>\n",
              "      <td>114</td>\n",
              "      <td>275</td>\n",
              "      <td>412</td>\n",
              "      <td>424</td>\n",
              "      <td>213</td>\n",
              "      <td>114</td>\n",
              "      <td>135</td>\n",
              "      <td>214</td>\n",
              "      <td>186</td>\n",
              "      <td>289</td>\n",
              "      <td>396</td>\n",
              "      <td>394</td>\n",
              "      <td>378</td>\n",
              "      <td>439</td>\n",
              "      <td>277</td>\n",
              "      <td>370</td>\n",
              "      <td>375</td>\n",
              "      <td>376</td>\n",
              "      <td>365</td>\n",
              "      <td>272</td>\n",
              "      <td>481</td>\n",
              "      <td>273</td>\n",
              "      <td>283</td>\n",
              "      <td>412</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_simpleimputer__strategy</th>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "      <td>median</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_targetencoder__min_samples_leaf</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_targetencoder__smoothing</th>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>60</td>\n",
              "      <td>1000</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>100</td>\n",
              "      <td>50</td>\n",
              "      <td>1000</td>\n",
              "      <td>100</td>\n",
              "      <td>1000</td>\n",
              "      <td>60</td>\n",
              "      <td>50</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>2</td>\n",
              "      <td>1000</td>\n",
              "      <td>50</td>\n",
              "      <td>500</td>\n",
              "      <td>1000</td>\n",
              "      <td>60</td>\n",
              "      <td>500</td>\n",
              "      <td>500</td>\n",
              "      <td>60</td>\n",
              "      <td>1000</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params</th>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 15, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 15, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 15, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 10, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 5, 'rando...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 15, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 15, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': 20, 'rand...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "      <td>{'randomforestregressor__max_depth': None, 'ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split0_test_score</th>\n",
              "      <td>-0.251603</td>\n",
              "      <td>-0.251523</td>\n",
              "      <td>-0.251606</td>\n",
              "      <td>-0.25164</td>\n",
              "      <td>-0.251657</td>\n",
              "      <td>-0.251695</td>\n",
              "      <td>-0.25169</td>\n",
              "      <td>-0.251691</td>\n",
              "      <td>-0.256126</td>\n",
              "      <td>-0.25618</td>\n",
              "      <td>-0.256238</td>\n",
              "      <td>-0.258794</td>\n",
              "      <td>-0.25889</td>\n",
              "      <td>-0.258944</td>\n",
              "      <td>-0.260488</td>\n",
              "      <td>-0.260709</td>\n",
              "      <td>-0.260749</td>\n",
              "      <td>-0.260919</td>\n",
              "      <td>-0.261858</td>\n",
              "      <td>-0.261908</td>\n",
              "      <td>-0.261863</td>\n",
              "      <td>-0.27091</td>\n",
              "      <td>-0.271179</td>\n",
              "      <td>-0.274228</td>\n",
              "      <td>-0.274191</td>\n",
              "      <td>-0.274198</td>\n",
              "      <td>-0.274312</td>\n",
              "      <td>-0.274339</td>\n",
              "      <td>-0.276297</td>\n",
              "      <td>-0.276596</td>\n",
              "      <td>-0.281349</td>\n",
              "      <td>-0.28135</td>\n",
              "      <td>-0.281431</td>\n",
              "      <td>-0.281487</td>\n",
              "      <td>-0.28147</td>\n",
              "      <td>-0.281413</td>\n",
              "      <td>-0.281664</td>\n",
              "      <td>-0.281739</td>\n",
              "      <td>-0.281462</td>\n",
              "      <td>-0.281683</td>\n",
              "      <td>-0.281751</td>\n",
              "      <td>-0.283961</td>\n",
              "      <td>-0.283801</td>\n",
              "      <td>-0.283958</td>\n",
              "      <td>-0.283908</td>\n",
              "      <td>-0.283946</td>\n",
              "      <td>-0.283897</td>\n",
              "      <td>-0.283875</td>\n",
              "      <td>-0.283899</td>\n",
              "      <td>-0.283909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split1_test_score</th>\n",
              "      <td>-0.248504</td>\n",
              "      <td>-0.248537</td>\n",
              "      <td>-0.248579</td>\n",
              "      <td>-0.248625</td>\n",
              "      <td>-0.248658</td>\n",
              "      <td>-0.248624</td>\n",
              "      <td>-0.248634</td>\n",
              "      <td>-0.248825</td>\n",
              "      <td>-0.253477</td>\n",
              "      <td>-0.25331</td>\n",
              "      <td>-0.253622</td>\n",
              "      <td>-0.255428</td>\n",
              "      <td>-0.255377</td>\n",
              "      <td>-0.255428</td>\n",
              "      <td>-0.258029</td>\n",
              "      <td>-0.25784</td>\n",
              "      <td>-0.25801</td>\n",
              "      <td>-0.258149</td>\n",
              "      <td>-0.259936</td>\n",
              "      <td>-0.259882</td>\n",
              "      <td>-0.260224</td>\n",
              "      <td>-0.26889</td>\n",
              "      <td>-0.268881</td>\n",
              "      <td>-0.271721</td>\n",
              "      <td>-0.271746</td>\n",
              "      <td>-0.271799</td>\n",
              "      <td>-0.271812</td>\n",
              "      <td>-0.27207</td>\n",
              "      <td>-0.274253</td>\n",
              "      <td>-0.274389</td>\n",
              "      <td>-0.279722</td>\n",
              "      <td>-0.279702</td>\n",
              "      <td>-0.279984</td>\n",
              "      <td>-0.280065</td>\n",
              "      <td>-0.279918</td>\n",
              "      <td>-0.280084</td>\n",
              "      <td>-0.279769</td>\n",
              "      <td>-0.279997</td>\n",
              "      <td>-0.28014</td>\n",
              "      <td>-0.279872</td>\n",
              "      <td>-0.279991</td>\n",
              "      <td>-0.282267</td>\n",
              "      <td>-0.28221</td>\n",
              "      <td>-0.282314</td>\n",
              "      <td>-0.282353</td>\n",
              "      <td>-0.282318</td>\n",
              "      <td>-0.282365</td>\n",
              "      <td>-0.282362</td>\n",
              "      <td>-0.282305</td>\n",
              "      <td>-0.282588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split2_test_score</th>\n",
              "      <td>-0.249328</td>\n",
              "      <td>-0.249494</td>\n",
              "      <td>-0.249523</td>\n",
              "      <td>-0.249549</td>\n",
              "      <td>-0.249558</td>\n",
              "      <td>-0.249558</td>\n",
              "      <td>-0.249555</td>\n",
              "      <td>-0.249495</td>\n",
              "      <td>-0.253901</td>\n",
              "      <td>-0.254051</td>\n",
              "      <td>-0.254067</td>\n",
              "      <td>-0.256127</td>\n",
              "      <td>-0.256162</td>\n",
              "      <td>-0.256205</td>\n",
              "      <td>-0.258374</td>\n",
              "      <td>-0.258501</td>\n",
              "      <td>-0.258626</td>\n",
              "      <td>-0.258582</td>\n",
              "      <td>-0.260394</td>\n",
              "      <td>-0.260449</td>\n",
              "      <td>-0.260376</td>\n",
              "      <td>-0.268718</td>\n",
              "      <td>-0.269212</td>\n",
              "      <td>-0.273056</td>\n",
              "      <td>-0.273185</td>\n",
              "      <td>-0.273184</td>\n",
              "      <td>-0.273195</td>\n",
              "      <td>-0.273306</td>\n",
              "      <td>-0.274343</td>\n",
              "      <td>-0.273961</td>\n",
              "      <td>-0.278809</td>\n",
              "      <td>-0.278925</td>\n",
              "      <td>-0.279125</td>\n",
              "      <td>-0.279071</td>\n",
              "      <td>-0.279418</td>\n",
              "      <td>-0.279342</td>\n",
              "      <td>-0.279425</td>\n",
              "      <td>-0.279197</td>\n",
              "      <td>-0.279356</td>\n",
              "      <td>-0.279407</td>\n",
              "      <td>-0.279228</td>\n",
              "      <td>-0.281065</td>\n",
              "      <td>-0.28138</td>\n",
              "      <td>-0.281315</td>\n",
              "      <td>-0.281363</td>\n",
              "      <td>-0.281368</td>\n",
              "      <td>-0.281387</td>\n",
              "      <td>-0.281449</td>\n",
              "      <td>-0.281483</td>\n",
              "      <td>-0.28129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_score</th>\n",
              "      <td>-0.249811</td>\n",
              "      <td>-0.249851</td>\n",
              "      <td>-0.249903</td>\n",
              "      <td>-0.249938</td>\n",
              "      <td>-0.249958</td>\n",
              "      <td>-0.249959</td>\n",
              "      <td>-0.24996</td>\n",
              "      <td>-0.250004</td>\n",
              "      <td>-0.254501</td>\n",
              "      <td>-0.254514</td>\n",
              "      <td>-0.254642</td>\n",
              "      <td>-0.256783</td>\n",
              "      <td>-0.25681</td>\n",
              "      <td>-0.256859</td>\n",
              "      <td>-0.258964</td>\n",
              "      <td>-0.259017</td>\n",
              "      <td>-0.259129</td>\n",
              "      <td>-0.259217</td>\n",
              "      <td>-0.260729</td>\n",
              "      <td>-0.260746</td>\n",
              "      <td>-0.260821</td>\n",
              "      <td>-0.269506</td>\n",
              "      <td>-0.269757</td>\n",
              "      <td>-0.273002</td>\n",
              "      <td>-0.273041</td>\n",
              "      <td>-0.27306</td>\n",
              "      <td>-0.273107</td>\n",
              "      <td>-0.273238</td>\n",
              "      <td>-0.274964</td>\n",
              "      <td>-0.274982</td>\n",
              "      <td>-0.27996</td>\n",
              "      <td>-0.279992</td>\n",
              "      <td>-0.28018</td>\n",
              "      <td>-0.280207</td>\n",
              "      <td>-0.280269</td>\n",
              "      <td>-0.28028</td>\n",
              "      <td>-0.280286</td>\n",
              "      <td>-0.280311</td>\n",
              "      <td>-0.280319</td>\n",
              "      <td>-0.280321</td>\n",
              "      <td>-0.280323</td>\n",
              "      <td>-0.282431</td>\n",
              "      <td>-0.282464</td>\n",
              "      <td>-0.282529</td>\n",
              "      <td>-0.282541</td>\n",
              "      <td>-0.282544</td>\n",
              "      <td>-0.28255</td>\n",
              "      <td>-0.282562</td>\n",
              "      <td>-0.282562</td>\n",
              "      <td>-0.282596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_test_score</th>\n",
              "      <td>0.0013107</td>\n",
              "      <td>0.00124509</td>\n",
              "      <td>0.00126455</td>\n",
              "      <td>0.0012615</td>\n",
              "      <td>0.00125644</td>\n",
              "      <td>0.00128541</td>\n",
              "      <td>0.00127993</td>\n",
              "      <td>0.00122387</td>\n",
              "      <td>0.00116171</td>\n",
              "      <td>0.00121648</td>\n",
              "      <td>0.00114274</td>\n",
              "      <td>0.00145017</td>\n",
              "      <td>0.00150568</td>\n",
              "      <td>0.00150799</td>\n",
              "      <td>0.00108704</td>\n",
              "      <td>0.00122685</td>\n",
              "      <td>0.00117328</td>\n",
              "      <td>0.00121657</td>\n",
              "      <td>0.000819881</td>\n",
              "      <td>0.000853116</td>\n",
              "      <td>0.00073918</td>\n",
              "      <td>0.000995513</td>\n",
              "      <td>0.00101453</td>\n",
              "      <td>0.00102435</td>\n",
              "      <td>0.00100371</td>\n",
              "      <td>0.000983053</td>\n",
              "      <td>0.00102238</td>\n",
              "      <td>0.000927493</td>\n",
              "      <td>0.000942837</td>\n",
              "      <td>0.00115441</td>\n",
              "      <td>0.00105036</td>\n",
              "      <td>0.00101106</td>\n",
              "      <td>0.000951366</td>\n",
              "      <td>0.000991597</td>\n",
              "      <td>0.000873506</td>\n",
              "      <td>0.000856768</td>\n",
              "      <td>0.000984686</td>\n",
              "      <td>0.00106103</td>\n",
              "      <td>0.000869379</td>\n",
              "      <td>0.000981754</td>\n",
              "      <td>0.00105634</td>\n",
              "      <td>0.00118814</td>\n",
              "      <td>0.00100471</td>\n",
              "      <td>0.00108987</td>\n",
              "      <td>0.00104756</td>\n",
              "      <td>0.00106444</td>\n",
              "      <td>0.00103279</td>\n",
              "      <td>0.00100074</td>\n",
              "      <td>0.00100288</td>\n",
              "      <td>0.00106915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_score</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>24</td>\n",
              "      <td>25</td>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>33</td>\n",
              "      <td>34</td>\n",
              "      <td>35</td>\n",
              "      <td>36</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>43</td>\n",
              "      <td>44</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>49</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                          25  ...                                                 28\n",
              "mean_fit_time                                                                        31.4534  ...                                            40.9381\n",
              "std_fit_time                                                                        0.424569  ...                                           0.330603\n",
              "mean_score_time                                                                     0.772504  ...                                            1.09684\n",
              "std_score_time                                                                     0.0108714  ...                                           0.061287\n",
              "param_randomforestregressor__max_depth                                                    10  ...                                               None\n",
              "param_randomforestregressor__n_estimators                                                242  ...                                                228\n",
              "param_simpleimputer__strategy                                                           mean  ...                                             median\n",
              "param_targetencoder__min_samples_leaf                                                      1  ...                                                  9\n",
              "param_targetencoder__smoothing                                                            50  ...                                                 20\n",
              "params                                     {'randomforestregressor__max_depth': 10, 'rand...  ...  {'randomforestregressor__max_depth': None, 'ra...\n",
              "split0_test_score                                                                  -0.251603  ...                                          -0.283909\n",
              "split1_test_score                                                                  -0.248504  ...                                          -0.282588\n",
              "split2_test_score                                                                  -0.249328  ...                                           -0.28129\n",
              "mean_test_score                                                                    -0.249811  ...                                          -0.282596\n",
              "std_test_score                                                                     0.0013107  ...                                         0.00106915\n",
              "rank_test_score                                                                            1  ...                                                 50\n",
              "\n",
              "[16 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoPlYbtbMkGi"
      },
      "source": [
        "# 만들어진 모델에거 가장 성능이 좋은 모델을 불러옵니다.\n",
        "\n",
        "pipe = clf.best_estimator_"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUWBlF-T_JGn"
      },
      "source": [
        "\n",
        "### 2) (도전과제🔥) [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 를 사용하여 하이퍼파라미터 튜닝을 진행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmG1vDWfKtL-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}